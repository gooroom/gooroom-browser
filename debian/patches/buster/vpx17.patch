description: maintain compatibility with vpx 1.7
author: Michael Gilbert <mgilbert@debian.org>

--- a/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.cc
+++ b/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.cc
@@ -216,39 +216,6 @@ std::unique_ptr<ScalableVideoController>
   return scalability_structure_controller;
 }
 
-vpx_svc_ref_frame_config_t Vp9References(
-    rtc::ArrayView<const ScalableVideoController::LayerFrameConfig> layers) {
-  vpx_svc_ref_frame_config_t ref_config = {};
-  for (const ScalableVideoController::LayerFrameConfig& layer_frame : layers) {
-    const auto& buffers = layer_frame.Buffers();
-    RTC_DCHECK_LE(buffers.size(), 3);
-    int sid = layer_frame.SpatialId();
-    if (!buffers.empty()) {
-      ref_config.lst_fb_idx[sid] = buffers[0].id;
-      ref_config.reference_last[sid] = buffers[0].referenced;
-      if (buffers[0].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[0].id);
-      }
-    }
-    if (buffers.size() > 1) {
-      ref_config.gld_fb_idx[sid] = buffers[1].id;
-      ref_config.reference_golden[sid] = buffers[1].referenced;
-      if (buffers[1].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[1].id);
-      }
-    }
-    if (buffers.size() > 2) {
-      ref_config.alt_fb_idx[sid] = buffers[2].id;
-      ref_config.reference_alt_ref[sid] = buffers[2].referenced;
-      if (buffers[2].updated) {
-        ref_config.update_buffer_slot[sid] |= (1 << buffers[2].id);
-      }
-    }
-  }
-  // TODO(bugs.webrtc.org/11999): Fill ref_config.duration
-  return ref_config;
-}
-
 }  // namespace
 
 void VP9EncoderImpl::EncoderOutputCodedPacketCallback(vpx_codec_cx_pkt* pkt,
@@ -455,15 +422,6 @@ bool VP9EncoderImpl::SetSvcRates(
     }
   }
 
-  if (higher_layers_enabled && !force_key_frame_) {
-    // Prohibit drop of all layers for the next frame, so newly enabled
-    // layer would have a valid spatial reference.
-    for (size_t i = 0; i < num_spatial_layers_; ++i) {
-      svc_drop_frame_.framedrop_thresh[i] = 0;
-    }
-    force_all_active_layers_ = true;
-  }
-
   if (svc_controller_) {
     VideoBitrateAllocation allocation;
     for (int sid = 0; sid < num_spatial_layers_; ++sid) {
@@ -810,8 +768,6 @@ int VP9EncoderImpl::InitAndSetControlSet
     for (int si = 0; si < num_spatial_layers_; ++si) {
       svc_params_.speed_per_layer[si] =
           performance_flags_by_spatial_index_[si].base_layer_speed;
-      svc_params_.loopfilter_ctrl[si] =
-          performance_flags_by_spatial_index_[si].deblock_mode;
     }
   }
 
@@ -821,7 +777,6 @@ int VP9EncoderImpl::InitAndSetControlSet
                     inst->VP9().adaptiveQpMode ? 3 : 0);
 
   vpx_codec_control(encoder_, VP9E_SET_FRAME_PARALLEL_DECODING, 0);
-  vpx_codec_control(encoder_, VP9E_SET_SVC_GF_TEMPORAL_REF, 0);
 
   if (is_svc_) {
     vpx_codec_control(encoder_, VP9E_SET_SVC, 1);
@@ -833,56 +788,6 @@ int VP9EncoderImpl::InitAndSetControlSet
         performance_flags_by_spatial_index_.rbegin()->base_layer_speed);
   }
 
-  if (num_spatial_layers_ > 1) {
-    switch (inter_layer_pred_) {
-      case InterLayerPredMode::kOn:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 0);
-        break;
-      case InterLayerPredMode::kOff:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 1);
-        break;
-      case InterLayerPredMode::kOnKeyPic:
-        vpx_codec_control(encoder_, VP9E_SET_SVC_INTER_LAYER_PRED, 2);
-        break;
-      default:
-        RTC_NOTREACHED();
-    }
-
-    memset(&svc_drop_frame_, 0, sizeof(svc_drop_frame_));
-    const bool reverse_constrained_drop_mode =
-        inter_layer_pred_ == InterLayerPredMode::kOn &&
-        codec_.mode == VideoCodecMode::kScreensharing &&
-        num_spatial_layers_ > 1;
-    if (reverse_constrained_drop_mode) {
-      // Screenshare dropping mode: drop a layer only together with all lower
-      // layers. This ensures that drops on lower layers won't reduce frame-rate
-      // for higher layers and reference structure is RTP-compatible.
-      svc_drop_frame_.framedrop_mode = CONSTRAINED_FROM_ABOVE_DROP;
-      svc_drop_frame_.max_consec_drop = 5;
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-      // No buffering is needed because the highest layer is always present in
-      // all frames in CONSTRAINED_FROM_ABOVE drop mode.
-      layer_buffering_ = false;
-    } else {
-      // Configure encoder to drop entire superframe whenever it needs to drop
-      // a layer. This mode is preferred over per-layer dropping which causes
-      // quality flickering and is not compatible with RTP non-flexible mode.
-      svc_drop_frame_.framedrop_mode =
-          full_superframe_drop_ ? FULL_SUPERFRAME_DROP : CONSTRAINED_LAYER_DROP;
-      // Buffering is needed only for constrained layer drop, as it's not clear
-      // which frame is the last.
-      layer_buffering_ = !full_superframe_drop_;
-      svc_drop_frame_.max_consec_drop = std::numeric_limits<int>::max();
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-    }
-    vpx_codec_control(encoder_, VP9E_SET_SVC_FRAME_DROP_LAYER,
-                      &svc_drop_frame_);
-  }
-
   // Register callback for getting each spatial layer.
   vpx_codec_priv_output_cx_pkt_cb_pair_t cbp = {
       VP9EncoderImpl::EncoderOutputCodedPacketCallback,
@@ -1025,52 +930,10 @@ int VP9EncoderImpl::Encode(const VideoFr
     }
   }
 
-  // Need to set temporal layer id on ALL layers, even disabled ones.
-  // Otherwise libvpx might produce frames on a disabled layer:
-  // http://crbug.com/1051476
-  for (int sl_idx = 0; sl_idx < num_spatial_layers_; ++sl_idx) {
-    layer_id.temporal_layer_id_per_spatial[sl_idx] = layer_id.temporal_layer_id;
-  }
-
   if (layer_id.spatial_layer_id < first_active_layer_) {
     layer_id.spatial_layer_id = first_active_layer_;
   }
 
-  if (svc_controller_) {
-    layer_id.spatial_layer_id = layer_frames_.front().SpatialId();
-    layer_id.temporal_layer_id = layer_frames_.front().TemporalId();
-    for (const auto& layer : layer_frames_) {
-      layer_id.temporal_layer_id_per_spatial[layer.SpatialId()] =
-          layer.TemporalId();
-    }
-  }
-
-  if (is_svc_ && performance_flags_.use_per_layer_speed) {
-    // Update speed settings that might depend on temporal index.
-    bool speed_updated = false;
-    for (int sl_idx = 0; sl_idx < num_spatial_layers_; ++sl_idx) {
-      const int target_speed =
-          layer_id.temporal_layer_id_per_spatial[sl_idx] == 0
-              ? performance_flags_by_spatial_index_[sl_idx].base_layer_speed
-              : performance_flags_by_spatial_index_[sl_idx].high_layer_speed;
-      if (svc_params_.speed_per_layer[sl_idx] != target_speed) {
-        svc_params_.speed_per_layer[sl_idx] = target_speed;
-        speed_updated = true;
-      }
-    }
-    if (speed_updated) {
-      vpx_codec_control(encoder_, VP9E_SET_SVC_PARAMETERS, &svc_params_);
-    }
-  }
-
-  vpx_codec_control(encoder_, VP9E_SET_SVC_LAYER_ID, &layer_id);
-
-  if (num_spatial_layers_ > 1) {
-    // Update frame dropping settings as they may change on per-frame basis.
-    vpx_codec_control(encoder_, VP9E_SET_SVC_FRAME_DROP_LAYER,
-                      &svc_drop_frame_);
-  }
-
   if (config_changed_) {
     if (vpx_codec_enc_config_set(encoder_, config_)) {
       return WEBRTC_VIDEO_CODEC_ERROR;
@@ -1112,19 +975,7 @@ int VP9EncoderImpl::Encode(const VideoFr
   rtc::scoped_refptr<const I010BufferInterface> i010_copy;
   switch (profile_) {
     case VP9Profile::kProfile0: {
-      if (input_image.video_frame_buffer()->type() ==
-          VideoFrameBuffer::Type::kNV12) {
-        const NV12BufferInterface* nv12_buffer =
-            input_image.video_frame_buffer()->GetNV12();
-        video_frame_buffer = nv12_buffer;
-        MaybeRewrapRawWithFormat(VPX_IMG_FMT_NV12);
-        raw_->planes[VPX_PLANE_Y] = const_cast<uint8_t*>(nv12_buffer->DataY());
-        raw_->planes[VPX_PLANE_U] = const_cast<uint8_t*>(nv12_buffer->DataUV());
-        raw_->planes[VPX_PLANE_V] = raw_->planes[VPX_PLANE_U] + 1;
-        raw_->stride[VPX_PLANE_Y] = nv12_buffer->StrideY();
-        raw_->stride[VPX_PLANE_U] = nv12_buffer->StrideUV();
-        raw_->stride[VPX_PLANE_V] = nv12_buffer->StrideUV();
-      } else {
+      if (true) {
         rtc::scoped_refptr<I420BufferInterface> i420_buffer =
             input_image.video_frame_buffer()->ToI420();
         video_frame_buffer = i420_buffer;
@@ -1176,24 +1027,6 @@ int VP9EncoderImpl::Encode(const VideoFr
     flags = VPX_EFLAG_FORCE_KF;
   }
 
-  if (svc_controller_) {
-    vpx_svc_ref_frame_config_t ref_config = Vp9References(layer_frames_);
-    vpx_codec_control(encoder_, VP9E_SET_SVC_REF_FRAME_CONFIG, &ref_config);
-  } else if (external_ref_control_) {
-    vpx_svc_ref_frame_config_t ref_config =
-        SetReferences(force_key_frame_, layer_id.spatial_layer_id);
-
-    if (VideoCodecMode::kScreensharing == codec_.mode) {
-      for (uint8_t sl_idx = 0; sl_idx < num_active_spatial_layers_; ++sl_idx) {
-        ref_config.duration[sl_idx] = static_cast<int64_t>(
-            90000 / (std::min(static_cast<float>(codec_.maxFramerate),
-                              framerate_controller_[sl_idx].GetTargetRate())));
-      }
-    }
-
-    vpx_codec_control(encoder_, VP9E_SET_SVC_REF_FRAME_CONFIG, &ref_config);
-  }
-
   first_frame_in_picture_ = true;
 
   // TODO(ssilkin): Frame duration should be specified per spatial layer
@@ -1300,11 +1133,7 @@ void VP9EncoderImpl::PopulateCodecSpecif
   vp9_info->first_active_layer = first_active_layer_;
 
   vp9_info->num_ref_pics = 0;
-  FillReferenceIndices(pkt, pics_since_key_, vp9_info->inter_layer_predicted,
-                       vp9_info);
-  if (vp9_info->flexible_mode) {
-    vp9_info->gof_idx = kNoGofIdx;
-  } else {
+  if (true) {
     vp9_info->gof_idx =
         static_cast<uint8_t>(pics_since_key_ % gof_.num_frames_in_gof);
     vp9_info->temporal_up_switch = gof_.temporal_up_switch[vp9_info->gof_idx];
@@ -1372,6 +1201,7 @@ void VP9EncoderImpl::PopulateCodecSpecif
   }
 }
 
+/*
 void VP9EncoderImpl::FillReferenceIndices(const vpx_codec_cx_pkt& pkt,
                                           const size_t pic_num,
                                           const bool inter_layer_predicted,
@@ -1624,6 +1454,7 @@ vpx_svc_ref_frame_config_t VP9EncoderImp
 
   return ref_config;
 }
+*/
 
 int VP9EncoderImpl::GetEncodedLayerFrame(const vpx_codec_cx_pkt* pkt) {
   RTC_DCHECK_EQ(pkt->kind, VPX_CODEC_CX_FRAME_PKT);
@@ -1665,14 +1496,10 @@ int VP9EncoderImpl::GetEncodedLayerFrame
                         input_image_->timestamp());
   encoded_image_.SetSpatialIndex(spatial_index);
 
-  UpdateReferenceBuffers(*pkt, pics_since_key_);
-
   TRACE_COUNTER1("webrtc", "EncodedFrameSize", encoded_image_.size());
   encoded_image_.SetTimestamp(input_image_->timestamp());
-  encoded_image_._encodedHeight =
-      pkt->data.frame.height[layer_id.spatial_layer_id];
-  encoded_image_._encodedWidth =
-      pkt->data.frame.width[layer_id.spatial_layer_id];
+  encoded_image_._encodedHeight = raw_->d_h;
+  encoded_image_._encodedWidth = raw_->d_w;
   int qp = -1;
   vpx_codec_control(encoder_, VP8E_GET_LAST_QUANTIZER, &qp);
   encoded_image_.qp_ = qp;
@@ -1688,14 +1515,6 @@ int VP9EncoderImpl::GetEncodedLayerFrame
 
 void VP9EncoderImpl::DeliverBufferedFrame(bool end_of_picture) {
   if (encoded_image_.size() > 0) {
-    if (num_spatial_layers_ > 1) {
-      // Restore frame dropping settings, as dropping may be temporary forbidden
-      // due to dynamically enabled layers.
-      for (size_t i = 0; i < num_spatial_layers_; ++i) {
-        svc_drop_frame_.framedrop_thresh[i] = config_->rc_dropframe_thresh;
-      }
-    }
-
     codec_specific_.end_of_picture = end_of_picture;
 
     encoded_complete_callback_->OnEncodedImage(encoded_image_,
@@ -1931,8 +1750,6 @@ void VP9EncoderImpl::MaybeRewrapRawWithF
   if (!raw_) {
     raw_ = vpx_img_wrap(nullptr, fmt, codec_.width, codec_.height, 1, nullptr);
   } else if (raw_->fmt != fmt) {
-    RTC_LOG(INFO) << "Switching VP9 encoder pixel format to "
-                  << (fmt == VPX_IMG_FMT_NV12 ? "NV12" : "I420");
     vpx_img_free(raw_);
     raw_ = vpx_img_wrap(nullptr, fmt, codec_.width, codec_.height, 1, nullptr);
   }
@@ -2028,14 +1845,6 @@ int VP9DecoderImpl::InitDecode(const Vid
     }
   }
 
-  vpx_codec_err_t status =
-      vpx_codec_control(decoder_, VP9D_SET_LOOP_FILTER_OPT, 1);
-  if (status != VPX_CODEC_OK) {
-    RTC_LOG(LS_ERROR) << "Failed to enable VP9D_SET_LOOP_FILTER_OPT. "
-                      << vpx_codec_error(decoder_);
-    return WEBRTC_VIDEO_CODEC_UNINITIALIZED;
-  }
-
   return WEBRTC_VIDEO_CODEC_OK;
 }
 
--- a/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.h
+++ b/third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.h
@@ -133,7 +133,6 @@ class VP9EncoderImpl : public VP9Encoder
   const bool trusted_rate_controller_;
   bool layer_buffering_;
   const bool full_superframe_drop_;
-  vpx_svc_frame_drop_t svc_drop_frame_;
   bool first_frame_in_picture_;
   VideoBitrateAllocation current_bitrate_allocation_;
   bool ss_info_needed_;
--- a/third_party/webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.cc
+++ b/third_party/webrtc/modules/video_coding/codecs/vp8/libvpx_vp8_encoder.cc
@@ -954,9 +954,6 @@ int LibvpxVp8Encoder::Encode(const Video
     case VideoFrameBuffer::Type::kI420:
       PrepareI420Image(input_image->GetI420());
       break;
-    case VideoFrameBuffer::Type::kNV12:
-      PrepareNV12Image(input_image->GetNV12());
-      break;
     default: {
       rtc::scoped_refptr<I420BufferInterface> i420_image =
           input_image->ToI420();
@@ -1240,8 +1237,6 @@ void LibvpxVp8Encoder::MaybeUpdatePixelF
         << "Not all raw images had the right format!";
     return;
   }
-  RTC_LOG(INFO) << "Updating vp8 encoder pixel format to "
-                << (fmt == VPX_IMG_FMT_NV12 ? "NV12" : "I420");
   for (size_t i = 0; i < raw_images_.size(); ++i) {
     vpx_image_t& img = raw_images_[i];
     auto d_w = img.d_w;
@@ -1288,7 +1283,6 @@ void LibvpxVp8Encoder::PrepareI420Image(
 
 void LibvpxVp8Encoder::PrepareNV12Image(const NV12BufferInterface* frame) {
   RTC_DCHECK(!raw_images_.empty());
-  MaybeUpdatePixelFormat(VPX_IMG_FMT_NV12);
   // Image in vpx_image_t format.
   // Input image is const. VP8's raw image is not defined as const.
   raw_images_[0].planes[VPX_PLANE_Y] = const_cast<uint8_t*>(frame->DataY());
--- a/media/gpu/vaapi/BUILD.gn
+++ b/media/gpu/vaapi/BUILD.gn
@@ -65,8 +65,6 @@ source_set("vaapi") {
     "vp8_vaapi_video_decoder_delegate.h",
     "vp9_encoder.cc",
     "vp9_encoder.h",
-    "vp9_rate_control.cc",
-    "vp9_rate_control.h",
     "vp9_temporal_layers.cc",
     "vp9_temporal_layers.h",
     "vp9_vaapi_video_decoder_delegate.cc",
@@ -81,7 +79,6 @@ source_set("vaapi") {
 
   configs += [
     "//build/config/linux/libva",
-    "//third_party/libvpx:libvpx_config",
   ]
 
   deps = [
@@ -96,7 +93,6 @@ source_set("vaapi") {
     "//media/gpu/chromeos:common",
     "//media/parsers",
     "//mojo/public/cpp/bindings",
-    "//third_party/libvpx:libvp9rc",
     "//third_party/libyuv",
     "//ui/gfx",
     "//ui/gfx/geometry",
@@ -218,7 +214,6 @@ source_set("unit_test") {
     "vp9_encoder_unittest.cc",
     "vp9_temporal_layers_unittest.cc",
   ]
-  configs += [ "//third_party/libvpx:libvpx_config" ]
   deps = [
     ":common",
     ":vaapi",
@@ -230,7 +225,6 @@ source_set("unit_test") {
     "//mojo/core/embedder",
     "//testing/gmock",
     "//testing/gtest",
-    "//third_party/libvpx:libvp9rc",
     "//ui/gfx:test_support",
     "//ui/gfx/geometry",
   ]
--- a/media/filters/vpx_video_decoder.cc
+++ b/media/filters/vpx_video_decoder.cc
@@ -242,13 +242,6 @@ bool VpxVideoDecoder::ConfigureDecoder(c
       return false;
     }
 
-    vpx_codec_err_t status =
-        vpx_codec_control(vpx_codec_.get(), VP9D_SET_LOOP_FILTER_OPT, 1);
-    if (status != VPX_CODEC_OK) {
-      DLOG(ERROR) << "Failed to enable VP9D_SET_LOOP_FILTER_OPT. "
-                  << vpx_codec_error(vpx_codec_.get());
-      return false;
-    }
   }
 
   if (config.alpha_mode() == VideoDecoderConfig::AlphaMode::kIsOpaque)
--- a/media/gpu/vaapi/vp9_encoder.cc
+++ b/media/gpu/vaapi/vp9_encoder.cc
@@ -12,7 +12,6 @@
 #include "media/gpu/macros.h"
 #include "media/gpu/vaapi/vp9_rate_control.h"
 #include "media/gpu/vaapi/vp9_temporal_layers.h"
-#include "third_party/libvpx/source/libvpx/vp9/ratectrl_rtc.h"
 
 namespace media {
 
@@ -114,47 +113,6 @@ VideoBitrateAllocation GetDefaultVideoBi
   return bitrate_allocation;
 }
 
-libvpx::VP9RateControlRtcConfig CreateRateControlConfig(
-    const gfx::Size encode_size,
-    const VP9Encoder::EncodeParams& encode_params,
-    const VideoBitrateAllocation& bitrate_allocation,
-    const size_t num_temporal_layers) {
-  libvpx::VP9RateControlRtcConfig rc_cfg{};
-  rc_cfg.width = encode_size.width();
-  rc_cfg.height = encode_size.height();
-  rc_cfg.max_quantizer =
-      QindexToQuantizer(encode_params.scaling_settings.max_qp);
-  rc_cfg.min_quantizer =
-      QindexToQuantizer(encode_params.scaling_settings.min_qp);
-  // libvpx::VP9RateControlRtcConfig is kbps.
-  rc_cfg.target_bandwidth = encode_params.bitrate_allocation.GetSumBps() / 1000;
-  // These default values come from
-  // //third_party/webrtc/modules/video_coding/codecs/vp9/vp9_impl.cc.
-  rc_cfg.buf_initial_sz = 500;
-  rc_cfg.buf_optimal_sz = 600;
-  rc_cfg.buf_sz = 1000;
-  rc_cfg.undershoot_pct = 50;
-  rc_cfg.overshoot_pct = 50;
-  rc_cfg.max_intra_bitrate_pct = MaxSizeOfKeyframeAsPercentage(
-      rc_cfg.buf_optimal_sz, encode_params.framerate);
-  rc_cfg.framerate = encode_params.framerate;
-
-  // Spatial layers variables.
-  rc_cfg.ss_number_layers = 1;
-  rc_cfg.scaling_factor_num[0] = 1;
-  rc_cfg.scaling_factor_den[0] = 1;
-  // Fill temporal layers variables.
-  rc_cfg.ts_number_layers = num_temporal_layers;
-  int bitrate_sum = 0;
-  for (size_t ti = 0; ti < num_temporal_layers; ti++) {
-    rc_cfg.max_quantizers[ti] = rc_cfg.max_quantizer;
-    rc_cfg.min_quantizers[ti] = rc_cfg.min_quantizer;
-    bitrate_sum += bitrate_allocation.GetBitrateBps(0, ti);
-    rc_cfg.layer_target_bitrate[ti] = bitrate_sum / 1000;
-    rc_cfg.ts_rate_decimator[ti] = 1u << (num_temporal_layers - ti - 1);
-  }
-  return rc_cfg;
-}
 }  // namespace
 
 VP9Encoder::EncodeParams::EncodeParams()
@@ -166,11 +124,6 @@ VP9Encoder::EncodeParams::EncodeParams()
       scaling_settings(kMinQP, kMaxQP),
       error_resilient_mode(false) {}
 
-void VP9Encoder::set_rate_ctrl_for_testing(
-    std::unique_ptr<VP9RateControl> rate_ctrl) {
-  rate_ctrl_ = std::move(rate_ctrl);
-}
-
 void VP9Encoder::Reset() {
   current_params_ = EncodeParams();
   reference_frames_.Clear();
@@ -226,22 +179,12 @@ bool VP9Encoder::Initialize(const VideoE
     }
     current_params_.scaling_settings.max_qp = kMaxQPForSoftwareRateCtrl;
 
-    // |rate_ctrl_| might be injected for tests.
-    if (!rate_ctrl_) {
-      rate_ctrl_ = VP9RateControl::Create(CreateRateControlConfig(
-          visible_size_, current_params_, initial_bitrate_allocation,
-          num_temporal_layers));
-    }
-    if (!rate_ctrl_)
-      return false;
   } else {
     if (config.HasTemporalLayer()) {
       DVLOGF(1) << "Temporal layer encoding works only when in "
                 << "kConstantQuantizationParameter";
       return false;
     }
-    DCHECK(!rate_ctrl_) << "|rate_ctrl_| should only be configured when in "
-                           "kConstantQuantizationParameter";
   }
 
   return UpdateRates(initial_bitrate_allocation,
@@ -309,14 +252,12 @@ BitstreamBufferMetadata VP9Encoder::GetM
 
 void VP9Encoder::BitrateControlUpdate(uint64_t encoded_chunk_size_bytes) {
   if (accelerator_->bitrate_control() !=
-          BitrateControl::kConstantQuantizationParameter ||
-      !rate_ctrl_) {
+          BitrateControl::kConstantQuantizationParameter) {
     DLOG(ERROR) << __func__ << "() is called when no bitrate controller exists";
     return;
   }
 
   DVLOGF(4) << "|encoded_chunk_size_bytes|=" << encoded_chunk_size_bytes;
-  rate_ctrl_->PostEncodeUpdate(encoded_chunk_size_bytes);
 }
 
 bool VP9Encoder::UpdateRates(const VideoBitrateAllocation& bitrate_allocation,
@@ -340,13 +281,8 @@ bool VP9Encoder::UpdateRates(const Video
       current_params_.bitrate_allocation.GetSumBps() *
       current_params_.cpb_window_size_ms / 1000;
 
-  if (!rate_ctrl_)
-    return true;
-
   const size_t num_temporal_layers =
       temporal_layers_ ? temporal_layers_->num_layers() : 1u;
-  rate_ctrl_->UpdateRateControl(CreateRateControlConfig(
-      visible_size_, current_params_, bitrate_allocation, num_temporal_layers));
   return true;
 }
 
@@ -397,21 +333,6 @@ void VP9Encoder::SetFrameHeader(
     }
   }
 
-  if (!rate_ctrl_)
-    return;
-
-  libvpx::VP9FrameParamsQpRTC frame_params{};
-  frame_params.frame_type =
-      keyframe ? FRAME_TYPE::KEY_FRAME : FRAME_TYPE::INTER_FRAME;
-  if (picture->metadata_for_encoding) {
-    frame_params.temporal_layer_id =
-        picture->metadata_for_encoding->temporal_idx;
-  }
-  rate_ctrl_->ComputeQP(frame_params);
-  picture->frame_hdr->quant_params.base_q_idx = rate_ctrl_->GetQP();
-  picture->frame_hdr->loop_filter.level = rate_ctrl_->GetLoopfilterLevel();
-  DVLOGF(4) << "qp=" << rate_ctrl_->GetQP()
-            << ", filter_level=" << rate_ctrl_->GetLoopfilterLevel();
 }
 
 void VP9Encoder::UpdateReferenceFrames(scoped_refptr<VP9Picture> picture) {
--- a/media/gpu/vaapi/vp9_encoder.h
+++ b/media/gpu/vaapi/vp9_encoder.h
@@ -20,7 +20,6 @@
 
 namespace media {
 class VP9TemporalLayers;
-class VP9RateControl;
 
 class VP9Encoder : public AcceleratedVideoEncoder {
  public:
@@ -101,8 +100,6 @@ class VP9Encoder : public AcceleratedVid
  private:
   friend class VP9EncoderTest;
 
-  void set_rate_ctrl_for_testing(std::unique_ptr<VP9RateControl> rate_ctrl);
-
   Vp9FrameHeader GetDefaultFrameHeader(const bool keyframe) const;
   void SetFrameHeader(bool keyframe,
                       VP9Picture* picture,
@@ -122,7 +119,6 @@ class VP9Encoder : public AcceleratedVid
   Vp9ReferenceFrameVector reference_frames_;
   std::unique_ptr<VP9TemporalLayers> temporal_layers_;
 
-  std::unique_ptr<VP9RateControl> rate_ctrl_;
   const std::unique_ptr<Accelerator> accelerator_;
 
   SEQUENCE_CHECKER(sequence_checker_);
--- a/third_party/blink/renderer/modules/mediarecorder/vpx_encoder.cc
+++ b/third_party/blink/renderer/modules/mediarecorder/vpx_encoder.cc
@@ -72,14 +72,6 @@ void VpxEncoder::EncodeOnEncodingTaskRun
   TRACE_EVENT0("media", "VpxEncoder::EncodeOnEncodingTaskRunner");
   DCHECK_CALLED_ON_VALID_SEQUENCE(encoding_sequence_checker_);
 
-  if (frame->format() == media::PIXEL_FORMAT_NV12 &&
-      frame->storage_type() == media::VideoFrame::STORAGE_GPU_MEMORY_BUFFER)
-    frame = WrapMappedGpuMemoryBufferVideoFrame(frame);
-  if (!frame) {
-    LOG(WARNING) << "Invalid video frame to encode";
-    return;
-  }
-
   const gfx::Size frame_size = frame->visible_rect().size();
   base::TimeDelta duration = EstimateFrameDuration(*frame);
   const media::WebmMuxer::VideoParameters video_params(frame);
@@ -95,18 +87,6 @@ void VpxEncoder::EncodeOnEncodingTaskRun
   std::string data;
   std::string alpha_data;
   switch (frame->format()) {
-    case media::PIXEL_FORMAT_NV12: {
-      last_frame_had_alpha_ = false;
-      DoEncode(encoder_.get(), frame_size, frame->data(VideoFrame::kYPlane),
-               frame->visible_data(VideoFrame::kYPlane),
-               frame->stride(VideoFrame::kYPlane),
-               frame->visible_data(VideoFrame::kUVPlane),
-               frame->stride(VideoFrame::kUVPlane),
-               frame->visible_data(VideoFrame::kUVPlane) + 1,
-               frame->stride(VideoFrame::kUVPlane), duration, force_keyframe,
-               data, &keyframe, VPX_IMG_FMT_NV12);
-      break;
-    }
     case media::PIXEL_FORMAT_I420: {
       last_frame_had_alpha_ = false;
       DoEncode(encoder_.get(), frame_size, frame->data(VideoFrame::kYPlane),
@@ -195,7 +175,7 @@ void VpxEncoder::DoEncode(vpx_codec_ctx_
                           bool* const keyframe,
                           vpx_img_fmt_t img_fmt) {
   DCHECK_CALLED_ON_VALID_SEQUENCE(encoding_sequence_checker_);
-  DCHECK(img_fmt == VPX_IMG_FMT_I420 || img_fmt == VPX_IMG_FMT_NV12);
+  DCHECK(img_fmt == VPX_IMG_FMT_I420);
 
   vpx_image_t vpx_image;
   vpx_image_t* const result =
